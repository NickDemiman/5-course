# Deep Lake

## Abstract
Традиционные озера данных обеспечивают критически важную инфраструктуру данных для аналитических процессов, позволяя перемещаться во времени, выполнять SQL запросы, получать данные с помощью транзакций ACID и визуализировать датасеты петабайтного масштаба в облачном хранилище.

Они позволяют организациям ликвидировать разрозненные хранилища данных, открыть возможности для принятия решений на основе данных., повысить операционную эффективность и сократить расходы.

Однако по мере того, как глубокое обучение берет верх над обычным аналитическими процессами, традиционные озера данных становятся менее полезными в таких областях, как обработка естественных языков (NLP), обработка звука, компьютерное зрение и в областях, вовлекающих нетабличные наборы данных.

Данная статья представляет Deep Lake, озеро данных для задач глубокого обучения с открытым исходным кодом, разработанным  на Activeloop. Deep Lake сохраняет преимущества стандартных озер данных с одной ключевой особенностью: оно хранит сложные данные, такие как изображения, видео, аннотации так же, как и табличные данные, в виде тензоров и быстро передает данные по сети в тензорный язык запросов, встроенный в браузер движок виртуализации или фреймворк глубокого обучения без ущерба использования GPU. Доступ к наборам данных, хранящимся в Deep Lake может быть получен при помощи PyTorch, TensorFlow, JAX.

## Introduction
Озеро данных - это центральный репозиторий, который дает организациям возможность хранить структурированные, неструктурированные и частично-структурированные данные в одном месте. Озера данных обеспечивают лучшие методы для управления и анализа данных. Вдобавок к этому, они дают возможность разбить хранилища данных и получить информацию, ранее скрытую в разрозненных источниках данных. Озера данных первого поколения традиционно хранили данные в распределенных хранилищах данных, таких как HDFS или AWS S3. Неорганизованные данные превратили озера данных в "болота данных", которые дали толчок к развитию озер данных второго поколения во главе с  Delta, Iceberg и Hudi. Они работают строго поверх стандартизированных структурированных форматов, таких как Parquet, ORC, Avro и представляют такие функции, как время в пути, транзакции ACID и эволюция схемы. Озера данных напрямую интегрируются с движками запросов, такими как Presto, Athena, Hive, Photon для обработки аналитических запросов. Также их можно подключить к фреймворкам типа Hadoop, Spark и Airflow для поддержки ETL пайплайнов. В свою очередь, интеграция озер данных с движками запросов с прозрачными вычислениями и распределенным хранением вылилось в появление таких систем, как Lakehouse, которые служат альтернативой хранилищам данных, таких как Snowflake, BigQuery, Redshit, Clickhouse.

За последнее десятилетие глубокое обучение опередило традиционные техники машинного обучения, вовлекающие неструктурированные и сложные данные, такие как текст, изображения, видео и аудио. Не только