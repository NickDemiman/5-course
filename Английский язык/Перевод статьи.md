# Deep Lake

## Abstract
Традиционные озера данных обеспечивают критически важную инфраструктуру данных для аналитических процессов, позволяя перемещаться во времени, выполнять SQL запросы, получать данные с помощью транзакций ACID и визуализировать датасеты петабайтного масштаба в облачном хранилище.

Они позволяют организациям ликвидировать разрозненные хранилища данных, открыть возможности для принятия решений на основе данных., повысить операционную эффективность и сократить расходы.

Однако по мере того, как глубокое обучение берет верх над обычным аналитическими процессами, традиционные озера данных становятся менее полезными в таких областях, как обработка естественных языков (NLP), обработка звука, компьютерное зрение и в областях, вовлекающих нетабличные наборы данных.

Данная статья представляет Deep Lake, озеро данных для задач глубокого обучения с открытым исходным кодом, разработанным  на Activeloop. Deep Lake сохраняет преимущества стандартных озер данных с одной ключевой особенностью: оно хранит сложные данные, такие как изображения, видео, аннотации так же, как и табличные данные, в виде тензоров и быстро передает данные по сети в тензорный язык запросов, встроенный в браузер движок виртуализации или фреймворк глубокого обучения без ущерба использования GPU. Доступ к наборам данных, хранящимся в Deep Lake может быть получен при помощи PyTorch, TensorFlow, JAX.

## Introduction
Озеро данных - это центральный репозиторий, который дает организациям возможность хранить структурированные, неструктурированные и частично-структурированные данные в одном месте. Озера данных обеспечивают лучшие методы для управления и анализа данных. Вдобавок к этому, они дают возможность разбить хранилища данных и получить информацию, ранее скрытую в разрозненных источниках данных. Озера данных первого поколения традиционно хранили данные в распределенных хранилищах данных, таких как HDFS или AWS S3. Неорганизованные данные превратили озера данных в "болота данных", которые дали толчок к развитию озер данных второго поколения во главе с  Delta, Iceberg и Hudi. Они работают строго поверх стандартизированных структурированных форматов, таких как Parquet, ORC, Avro и представляют такие функции, как время в пути, транзакции ACID и эволюция схемы. Озера данных напрямую интегрируются с движками запросов, такими как Presto, Athena, Hive, Photon для обработки аналитических запросов. Также их можно подключить к фреймворкам типа Hadoop, Spark и Airflow для поддержки ETL пайплайнов. В свою очередь, интеграция озер данных с движками запросов с прозрачными вычислениями и распределенным хранением вылилось в появление таких систем, как Lakehouse, которые служат альтернативой хранилищам данных, таких как Snowflake, BigQuery, Redshit, Clickhouse.

За последнее десятилетие глубокое обучение опередило традиционные техники машинного обучения, вовлекающие неструктурированные и сложные данные, такие как текст, изображения, видео и аудио. Системы глубокого обучения не только переросли традиционные техники, но также достигли сверхчеловеческой точности в таких задачах, как определение рака по рентгеновским снимкам, анатомическая реконструкция нейронных клеток человека, игра в игры, вождение автомобиля, разворачивание белков и генерация изображений. Большие языковые модели с архитектурой, основанной на трансформациях, достигли высококлассных результатов в переводе, определении смысла, подведении итогов и дополнении текста. Большие мульти-модальные сети встраивают неструктурированные данные в векторы для кросс-модального поиска. Более того, они используются для создания фотореалистичных изображений из текста. Хотя одним из главных факторов успеха моделей глубокого обучения была доступность крупных датасетов, таких как CoCo, ImageNet, Oscar, LAION, они не имеют хорошо выстроенной инфраструктуры данных, схожей с традиционными аналитическими  рабочими нагрузками для поддержки такого машстаба. С другой стороны, в Modern Data Stack нет функций, необходимых для развертывания эффективных решений на базе глубокого обучения, поэтому организации выбрали разработку собственных систем.

В данной статье мы представляет Deep Lake, озеро данных разработанное специально для задач глубокого обучения. Deep Lake имеет преимущества традиционных озер данных с одним заметным отличие: оно хранит сложные данные типа изображений, видео, аннотаций и табличных данных в виде тензоров и обеспечивает быструю потоковую передачу данных в фреймворки глубокого обучения по сети без ущерба использования GPU. Более того, оно обеспечивает естественную совместимость между такими фреймворками для глубокого обучения, как PyTorch, TensorFlow и JAX.

Оставшаяся часть статьи разворачивается следующим образом. Мы начнем с рассмотрения текущих задач глубокого обучения на неструктурированных данных. Далее мы представим формат хранения Deep Lake и его ключевые концепты. Кроме того, мы обсудим возможности Deep Lake и его применение в цикле машинного обучения. Далее мы предоставим результаты экспериментов по прозводительности и обсудим результаты. В конце концов, мы рассмотрим связанные статьи, опишем возможные ограничения и сделаем выводы.

## Текущие задачи
В данном разделе мы обсудим текущие и исторические задачи по управлению неструктурированными и сложными данными.

### Сложные типы данных в базах данных
Есть 3 всеми признанных причины, почему blob или двоичные данные, такие как изображения, не должны храниться в БД. В первую очередь, базы данных обычно используют построчную архитектуру хранения. Поэтому выполнение запросов становится значительно медленнее, если строка содержит большое количество данных. Во вторых, сохранение данных в горячей памяти более затратно по сравнению с холодными хранением. И наконец, хранение изображений в оперативной памяти может быстро превысить емкость памяти и вызвать падение БД. По сути это делает широко используемые инфраструктуры данных неподходящими для обработки 